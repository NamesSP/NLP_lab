{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fe8e300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      " Word token:  ['There', 'are', 'multiple', 'ways', 'we', 'can', 'perform', 'tokenization', 'on', 'given', 'text', 'data.', 'we', 'will', 'be', 'considering', 'python', 'inbuilt', 'library.', 'we', 'can', 'choose', 'any', 'method', 'based', 'on', 'language,library', 'and', 'purpose', 'of', 'modeling.']\n",
      "\n",
      "\n",
      "sentence token:  ['There are multiple ways we can perform tokenization on given text data', ' we will be considering python inbuilt library', ' we can choose any method based on language,library and purpose of modeling', ''] \n",
      "---------------\n",
      "\n",
      "b\n",
      " word token:  ['There', 'are', 'multiple', 'ways', 'we', 'can', 'perform', 'tokenization', 'on', 'given', 'text', 'data', 'we', 'will', 'be', 'considering', 'python', 'inbuilt', 'library', 'we', 'can', 'choose', 'any', 'method', 'based', 'on', 'language', 'library', 'and', 'purpose', 'of', 'modeling']\n",
      "\n",
      "\n",
      "Sentence token:  ['There are multiple ways we can perform tokenization on given text data', ' we will be considering python inbuilt library', ' we can choose any method based on language,library and purpose of modeling', ''] \n",
      "---------------\n",
      "\n",
      "c\n",
      " word token:  ['There', 'are', 'multiple', 'ways', 'we', 'can', 'perform', 'tokenization', 'on', 'given', 'text', 'data', '.', 'we', 'will', 'be', 'considering', 'python', 'inbuilt', 'library', '.', 'we', 'can', 'choose', 'any', 'method', 'based', 'on', 'language', ',', 'library', 'and', 'purpose', 'of', 'modeling', '.']\n",
      "\n",
      "\n",
      "Sentence token:  ['There are multiple ways we can perform tokenization on given text data.', 'we will be considering python inbuilt library.', 'we can choose any method based on language,library and purpose of modeling.'] \n",
      "---------------\n",
      "\n",
      "d\n",
      " word token:  ['There', 'are', 'multiple', 'ways', 'we', 'can', 'perform', 'tokenization', 'on', 'given', 'text', 'data', '.', 'we', 'will', 'be', 'considering', 'python', 'inbuilt', 'library', '.', 'we', 'can', 'choose', 'any', 'method', 'based', 'on', 'language', ',', 'library', 'and', 'purpose', 'of', 'modeling', '.']\n",
      "\n",
      "\n",
      "Sentence token:  ['There are multiple ways we can perform tokenization on given text data.', 'we will be considering python inbuilt library.', 'we can choose any method based on language,library and purpose of modeling.'] \n",
      "---------------\n",
      "\n",
      "e\n",
      " word token:  ['there', 'are', 'multiple', 'ways', 'we', 'can', 'perform', 'tokenization', 'on', 'given', 'text', 'data', 'we', 'will', 'be', 'considering', 'python', 'inbuilt', 'library', 'we', 'can', 'choose', 'any', 'method', 'based', 'on', 'language', 'library', 'and', 'purpose', 'of', 'modeling']\n",
      "\n",
      "\n",
      "Sentence token:  ['there are multiple ways we can perform tokenization on given text data', ' we will be considering python inbuilt library', ' we can choose any method based on language', 'library and purpose of modeling'] \n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a. tokenization uding python's inbuilt method\n",
    "# b. using REgular expressions (RegEx)\n",
    "# c. using NLTK\n",
    "# d. usinbg SpaCy\n",
    "# e.using keras\n",
    "# check using spacy and display msg for every token.\n",
    "\n",
    "\n",
    "# a.pyhtons inbuilt method\n",
    "text=\"There are multiple ways we can perform tokenization on given text data. we will be considering python inbuilt library. we can choose any method based on language,library and purpose of modeling.\"\n",
    "word=text.split()\n",
    "sentence=text.split(\".\")\n",
    "print('a\\n','Word token: ',word)\n",
    "print('\\n')\n",
    "print('sentence token: ',sentence,'\\n---------------\\n')\n",
    "\n",
    "\n",
    "# b.RegEx\n",
    "import re\n",
    "word=re.findall('[\\w]+',text)\n",
    "sent=re.compile('[.]').split(text)\n",
    "print('b\\n','word token: ',word)\n",
    "print('\\n')\n",
    "print('Sentence token: ',sent,'\\n---------------\\n')\n",
    "\n",
    "# c.NLTK\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "word=word_tokenize(text)\n",
    "sent=sent_tokenize(text)\n",
    "print('c\\n','word token: ',word)\n",
    "print('\\n')\n",
    "print('Sentence token: ',sent,'\\n---------------\\n')\n",
    "\n",
    "# d.Spacy\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "doc=nlp(text)\n",
    "word=[]\n",
    "for t in doc:\n",
    "    word.append(t.text)\n",
    "sent=[]\n",
    "for t in doc.sents:\n",
    "    sent.append(t.text)\n",
    "print('d\\n','word token: ',word)\n",
    "print('\\n')\n",
    "print('Sentence token: ',sent,'\\n---------------\\n')\n",
    "\n",
    "# e. keras\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "word=text_to_word_sequence(text)\n",
    "sent=text_to_word_sequence(text,split=\".\")\n",
    "print('e\\n','word token: ',word)\n",
    "print('\\n')\n",
    "print('Sentence token: ',sent,'\\n---------------\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95b1964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "are \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "multiple \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "ways \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "we \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "can \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "perform \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "tokenization \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "on \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "given \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "text \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "data \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      ". \n",
      "is_alpha:  False \n",
      "is_punct:  True \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "we \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "will \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "be \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "considering \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "python \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "inbuilt \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "library \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      ". \n",
      "is_alpha:  False \n",
      "is_punct:  True \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "we \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "can \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "choose \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "any \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "method \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "based \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "on \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "language \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      ", \n",
      "is_alpha:  False \n",
      "is_punct:  True \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "library \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "and \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "purpose \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "of \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      "modeling \n",
      "is_alpha:  True \n",
      "is_punct:  False \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n",
      ". \n",
      "is_alpha:  False \n",
      "is_punct:  True \n",
      "like_num:  False \n",
      "is_currency:  False \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for t in doc:\n",
    "    print(t,\"\\nis_alpha: \",t.is_alpha,\n",
    "         \"\\nis_punct: \",t.is_punct,\n",
    "         \"\\nlike_num: \",t.like_num,\n",
    "         \"\\nis_currency: \",t.is_currency,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67137f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "There"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1dec741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token=doc[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d6934a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6a5a8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5807e16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0ca66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
